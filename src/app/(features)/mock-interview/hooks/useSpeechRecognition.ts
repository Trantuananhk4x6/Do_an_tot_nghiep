import { useState, useRef, useCallback, useEffect } from "react";

interface SpeechRecognitionHook {
  isListening: boolean;
  isSupported: boolean;
  startListening: () => void;
  stopListening: () => void;
  transcript: string;
  error: string | null;
  resetTranscript: () => void;
}

export const useSpeechRecognition = (
  onTranscript?: (text: string) => void,
  language: string = 'en-US'
): SpeechRecognitionHook => {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [error, setError] = useState<string | null>(null);
  const [isSupported, setIsSupported] = useState(false);
  const recognitionRef = useRef<any>(null);
  const timeoutRef = useRef<NodeJS.Timeout | null>(null);
  const callbackRef = useRef(onTranscript); // ‚úÖ S·ª≠ d·ª•ng ref cho callback

  // ‚úÖ C·∫≠p nh·∫≠t callback ref
  useEffect(() => {
    callbackRef.current = onTranscript;
  }, [onTranscript]);

  useEffect(() => {
    if (typeof window !== 'undefined') {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      
      if (SpeechRecognition) {
        console.log('‚úÖ Speech Recognition supported');
        setIsSupported(true);
        recognitionRef.current = new SpeechRecognition();
        const recognition = recognitionRef.current;

        // ‚úÖ C·∫•u h√¨nh gi·ªëng test th√†nh c√¥ng
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = language;
        recognition.maxAlternatives = 1;

        recognition.onstart = () => {
          console.log('üé§ Speech recognition STARTED');
          setIsListening(true);
          setError(null);
          
          // ‚úÖ Auto stop sau 30 gi√¢y
          timeoutRef.current = setTimeout(() => {
            console.log('‚è∞ Auto stopping after timeout');
            recognition.stop();
          }, 30000);
        };

        recognition.onresult = (event: any) => {
          console.log('üìä Speech recognition onresult event:', event);
          console.log('Results length:', event.results.length);
          
          // ‚úÖ Reset timeout ƒë·ªÉ ti·∫øp t·ª•c ghi n·∫øu user ƒëang n√≥i
          if (timeoutRef.current) {
            clearTimeout(timeoutRef.current);
            // ‚úÖ Auto stop sau 30 gi√¢y
            timeoutRef.current = setTimeout(() => {
              console.log('‚è∞ Auto stopping after timeout');
              recognition.stop();
            }, 30000);
          }
          
          let fullTranscript = '';
          
          // ‚úÖ GHI L·∫†I TO√ÄN B·ªò t·ª´ ƒë·∫ßu ƒë·∫øn gi·ªù (nh∆∞ YouTube/Google)
          for (let i = 0; i < event.results.length; i++) {
            const result = event.results[i];
            const transcript = result[0].transcript;
            
            console.log(`Result ${i}:`, {
              transcript,
              isFinal: result.isFinal,
              confidence: result[0].confidence
            });
            
            // N·ªëi t·∫•t c·∫£ c√°c transcript l·∫°i
            fullTranscript += transcript + ' ';
          }
          
          fullTranscript = fullTranscript.trim();
          console.log('üìù Full transcript so far:', fullTranscript);
          
          if (fullTranscript && fullTranscript.length > 0) {
            // ‚úÖ Ch·ªâ update transcript, KH√îNG t·ª± ƒë·ªông g·ª≠i
            setTranscript(fullTranscript);
            
            // ‚úÖ G·ªçi callback ƒë·ªÉ update UI real-time
            if (callbackRef.current) {
              console.log('üìû Updating transcript (not submitting):', fullTranscript);
              callbackRef.current(fullTranscript);
            }
            // ‚úÖ B·ªé auto stop - ch·ªâ stop khi user b·∫•m button
          }
        };

        recognition.onerror = (event: any) => {
          console.error('‚ùå Speech recognition error:', event.error, event);
          
          if (timeoutRef.current) {
            clearTimeout(timeoutRef.current);
          }
          
          // ‚úÖ Ch·ªâ restart cho l·ªói no-speech, gi·ªØ l·∫°i transcript c≈©
          if (event.error === 'no-speech') {
            console.log('üîÑ No speech detected, but keeping transcript');
            // Kh√¥ng set error ƒë·ªÉ kh√¥ng l√†m m·∫•t transcript
            setTimeout(() => {
              if (recognitionRef.current && isListening) {
                try {
                  recognitionRef.current.start();
                } catch (e) {
                  console.error('Failed to restart:', e);
                  setIsListening(false);
                }
              }
            }, 500);
          } else if (event.error === 'aborted') {
            // User ch·ªß ƒë·ªông d·ª´ng, kh√¥ng c·∫ßn b√°o l·ªói
            console.log('‚úÖ Recognition aborted by user');
            setIsListening(false);
          } else {
            setError(`Speech error: ${event.error}`);
            setIsListening(false);
          }
        };

        recognition.onend = () => {
          console.log('üõë Speech recognition ENDED');
          setIsListening(false);
          
          if (timeoutRef.current) {
            clearTimeout(timeoutRef.current);
          }
        };

        // ‚úÖ Debug events
        recognition.onspeechstart = () => console.log('üó£Ô∏è Speech detected!');
        recognition.onspeechend = () => console.log('ü§ê Speech ended');
        recognition.onsoundstart = () => console.log('üîä Sound detected');
        recognition.onsoundend = () => console.log('üîá Sound ended');

      } else {
        console.error('‚ùå Speech Recognition NOT supported');
        setIsSupported(false);
        setError('Speech recognition not supported');
      }
    }

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.abort();
      }
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
      }
    };
  }, [language]); // eslint-disable-line react-hooks/exhaustive-deps

  const startListening = useCallback(() => {
    console.log('üöÄ startListening called, isListening:', isListening);
    
    if (recognitionRef.current && !isListening) {
      try {
        setError(null);
        setTranscript('');
        console.log('üéØ Actually starting recognition...');
        recognitionRef.current.start();
      } catch (error) {
        console.error('‚ùå Error starting recognition:', error);
        setError('Failed to start speech recognition');
      }
    } else {
      console.log('‚ö†Ô∏è Cannot start - already listening or no recognition available');
    }
  }, [isListening]);

  const stopListening = useCallback(() => {
    console.log('‚èπÔ∏è stopListening called, isListening:', isListening);
    
    if (timeoutRef.current) {
      clearTimeout(timeoutRef.current);
    }
    
    if (recognitionRef.current && isListening) {
      recognitionRef.current.stop();
    }
  }, [isListening]);

  const resetTranscript = useCallback(() => {
    setTranscript('');
    setError(null);
  }, []);

  return {
    isListening,
    transcript,
    error,
    startListening,
    stopListening,
    resetTranscript,
    isSupported
  };
};