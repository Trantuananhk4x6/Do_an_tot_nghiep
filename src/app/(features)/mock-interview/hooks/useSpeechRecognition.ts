import { useState, useRef, useCallback, useEffect } from "react";

interface SpeechRecognitionHook {
  isListening: boolean;
  isSupported: boolean;
  startListening: () => void;
  stopListening: () => void;
  transcript: string;
  error: string | null;
  resetTranscript: () => void;
}

export const useSpeechRecognition = (
  onTranscript?: (text: string) => void,
  language: string = 'en-US'
): SpeechRecognitionHook => {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [error, setError] = useState<string | null>(null);
  const [isSupported, setIsSupported] = useState(false);
  const recognitionRef = useRef<any>(null);
  const timeoutRef = useRef<NodeJS.Timeout | null>(null);
  const callbackRef = useRef(onTranscript); // ‚úÖ S·ª≠ d·ª•ng ref cho callback

  // ‚úÖ C·∫≠p nh·∫≠t callback ref
  useEffect(() => {
    callbackRef.current = onTranscript;
  }, [onTranscript]);

  useEffect(() => {
    if (typeof window !== 'undefined') {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      
      if (SpeechRecognition) {
        console.log('‚úÖ Speech Recognition supported');
        setIsSupported(true);
        recognitionRef.current = new SpeechRecognition();
        const recognition = recognitionRef.current;

        // ‚úÖ C·∫•u h√¨nh gi·ªëng test th√†nh c√¥ng
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = language;
        recognition.maxAlternatives = 1;
        
        console.log('üé§ Speech Recognition configured:', {
          continuous: recognition.continuous,
          interimResults: recognition.interimResults,
          lang: recognition.lang,
          maxAlternatives: recognition.maxAlternatives
        });

        recognition.onstart = () => {
          console.log('üé§ Speech recognition STARTED');
          setIsListening(true);
          setError(null);
          
          // ‚úÖ Auto stop sau 30 gi√¢y
          timeoutRef.current = setTimeout(() => {
            console.log('‚è∞ Auto stopping after timeout');
            recognition.stop();
          }, 30000);
        };

        recognition.onresult = (event: any) => {
          console.log('üìä Speech recognition onresult event:', event);
          console.log('Results length:', event.results.length);
          
          // ‚úÖ Reset timeout ƒë·ªÉ ti·∫øp t·ª•c ghi n·∫øu user ƒëang n√≥i
          if (timeoutRef.current) {
            clearTimeout(timeoutRef.current);
            // ‚úÖ Auto stop sau 30 gi√¢y
            timeoutRef.current = setTimeout(() => {
              console.log('‚è∞ Auto stopping after timeout');
              recognition.stop();
            }, 30000);
          }
          
          let fullTranscript = '';
          
          // ‚úÖ GHI L·∫†I TO√ÄN B·ªò t·ª´ ƒë·∫ßu ƒë·∫øn gi·ªù (nh∆∞ YouTube/Google)
          for (let i = 0; i < event.results.length; i++) {
            const result = event.results[i];
            const transcript = result[0].transcript;
            
            console.log(`Result ${i}:`, {
              transcript,
              isFinal: result.isFinal,
              confidence: result[0].confidence
            });
            
            // N·ªëi t·∫•t c·∫£ c√°c transcript l·∫°i
            fullTranscript += transcript + ' ';
          }
          
          fullTranscript = fullTranscript.trim();
          console.log('üìù Full transcript so far:', fullTranscript);
          
          if (fullTranscript && fullTranscript.length > 0) {
            // ‚úÖ Ch·ªâ update transcript, KH√îNG t·ª± ƒë·ªông g·ª≠i
            setTranscript(fullTranscript);
            
            // ‚úÖ G·ªçi callback ƒë·ªÉ update UI real-time
            if (callbackRef.current) {
              console.log('üìû Updating transcript (not submitting):', fullTranscript);
              callbackRef.current(fullTranscript);
            }
            // ‚úÖ B·ªé auto stop - ch·ªâ stop khi user b·∫•m button
          }
        };

        recognition.onerror = (event: any) => {
          // ‚úÖ X·ª≠ l√Ω error d·ª±a tr√™n type
          if (event.error === 'no-speech') {
            // ‚ö†Ô∏è Kh√¥ng ph·∫£i l·ªói nghi√™m tr·ªçng - ch·ªâ l√† kh√¥ng nghe th·∫•y gi·ªçng n√≥i
            console.warn('‚ö†Ô∏è No speech detected, waiting for audio input...');
            
            // ‚ùå KH√îNG restart - ƒë·ªÉ recognition t·ª± x·ª≠ l√Ω!
            // Recognition s·∫Ω t·ª± ƒë·ªông ti·∫øp t·ª•c l·∫Øng nghe v√¨ continuous = true
            // Restart li√™n t·ª•c s·∫Ω l√†m n√≥ kh√¥ng k·ªãp nghe gi·ªçng n√≥i
            
            setError('ƒêang l·∫Øng nghe... H√£y b·∫Øt ƒë·∫ßu n√≥i');
            // Kh√¥ng set isListening = false, v·∫´n ƒë·ªÉ = true
            
          } else if (event.error === 'aborted') {
            // User ch·ªß ƒë·ªông d·ª´ng, kh√¥ng c·∫ßn b√°o l·ªói
            console.log('‚úÖ Recognition stopped by user');
            setIsListening(false);
            
            if (timeoutRef.current) {
              clearTimeout(timeoutRef.current);
            }
          } else if (event.error === 'audio-capture') {
            console.error('‚ùå Microphone access error - check permissions');
            setError('Kh√¥ng th·ªÉ truy c·∫≠p microphone. Vui l√≤ng ki·ªÉm tra quy·ªÅn truy c·∫≠p.');
            setIsListening(false);
            
            if (timeoutRef.current) {
              clearTimeout(timeoutRef.current);
            }
          } else if (event.error === 'not-allowed') {
            console.error('‚ùå Microphone permission denied');
            setError('B·∫°n c·∫ßn c·∫•p quy·ªÅn truy c·∫≠p microphone ƒë·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng n√†y.');
            setIsListening(false);
            
            if (timeoutRef.current) {
              clearTimeout(timeoutRef.current);
            }
          } else {
            // C√°c l·ªói kh√°c
            console.error('‚ùå Speech recognition error:', event.error, event);
            setError(`L·ªói nh·∫≠n d·∫°ng gi·ªçng n√≥i: ${event.error}`);
            setIsListening(false);
            
            if (timeoutRef.current) {
              clearTimeout(timeoutRef.current);
            }
          }
        };

        recognition.onend = () => {
          console.log('üõë Speech recognition ENDED');
          setIsListening(false);
          
          if (timeoutRef.current) {
            clearTimeout(timeoutRef.current);
          }
        };

        // ‚úÖ Debug events
        recognition.onspeechstart = () => console.log('üó£Ô∏è Speech detected!');
        recognition.onspeechend = () => console.log('ü§ê Speech ended');
        recognition.onsoundstart = () => console.log('üîä Sound detected');
        recognition.onsoundend = () => console.log('üîá Sound ended');

      } else {
        console.error('‚ùå Speech Recognition NOT supported');
        setIsSupported(false);
        setError('Speech recognition not supported');
      }
    }

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.abort();
      }
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
      }
    };
  }, [language]);

  const startListening = useCallback(() => {
    console.log('üöÄ startListening called, isListening:', isListening);
    
    if (recognitionRef.current && !isListening) {
      try {
        setError(null);
        setTranscript('');
        console.log('üéØ Actually starting recognition...');
        recognitionRef.current.start();
      } catch (error) {
        console.error('‚ùå Error starting recognition:', error);
        setError('Failed to start speech recognition');
      }
    } else {
      console.log('‚ö†Ô∏è Cannot start - already listening or no recognition available');
    }
  }, [isListening]);

  const stopListening = useCallback(() => {
    console.log('‚èπÔ∏è stopListening called, isListening:', isListening);
    
    if (timeoutRef.current) {
      clearTimeout(timeoutRef.current);
    }
    
    if (recognitionRef.current && isListening) {
      recognitionRef.current.stop();
    }
  }, [isListening]);

  const resetTranscript = useCallback(() => {
    setTranscript('');
    setError(null);
  }, []);

  return {
    isListening,
    transcript,
    error,
    startListening,
    stopListening,
    resetTranscript,
    isSupported
  };
};